# app.py
import os
import streamlit as st
from dotenv import load_dotenv

from langchain_openai import ChatOpenAI
from langchain_community.tools.tavily_search import TavilySearchResults
from langchain_community.utilities.arxiv import ArxivAPIWrapper

# =========================
# 0) í™˜ê²½ ë¡œë“œ
# =========================
load_dotenv()
OPENAI_API_KEY = os.getenv("OPENAI_API_KEY", "")
TAVILY_API_KEY = os.getenv("TAVILY_API_KEY", "")

# =========================
# 1) Agent ì—†ì´ ë‹¨ìˆœ ê²€ìƒ‰ í•¨ìˆ˜
# =========================
def tavily_search(query: str, max_results: int = 5):
    if not TAVILY_API_KEY:
        return "âš ï¸ TAVILY_API_KEY ì—†ìŒ"
    tavily = TavilySearchResults(max_results=max_results)
    return tavily.run(query)

def arxiv_search(query: str, top_k: int = 10):
    arxiv = ArxivAPIWrapper(top_k_results=top_k, load_max_docs=10)
    return arxiv.run(query)

# =========================
# 2) LLM
# =========================
def generate_article(topic, web_notes, paper_notes, model="gpt-4o-mini", temperature=0.2):
    llm = ChatOpenAI(model=model, temperature=temperature, api_key=OPENAI_API_KEY)
    system_msg = """ë‹¹ì‹ ì€ í•œêµ­ì–´ ë¸”ë¡œê±°ì´ì SEO ì „ë¬¸ê°€ì…ë‹ˆë‹¤.
ì£¼ì œì™€ ìë£Œë¥¼ ë°”íƒ•ìœ¼ë¡œ í‹°ìŠ¤í† ë¦¬ ë¸”ë¡œê·¸ì— ë°”ë¡œ ê²Œì‹œí•  ìˆ˜ ìˆëŠ” ë§ˆí¬ë‹¤ìš´ ê¸€ì„ ì‘ì„±í•˜ì„¸ìš”.
- ì œëª©
- í‚¤ì›Œë“œ
- ê°œìš”
- ë³¸ë¬¸ (ì†Œì œëª© í¬í•¨)
- FAQ
- ì¶œì²˜ ë§í¬
- ë§ˆë¬´ë¦¬"""
    user_msg = f"""
[ì£¼ì œ]
{topic}

[ì›¹ ê²€ìƒ‰ ìš”ì•½]
{web_notes}

[ë…¼ë¬¸ ê²€ìƒ‰ ìš”ì•½]
{paper_notes}
"""
    resp = llm.invoke([{"role": "system", "content": system_msg},
                       {"role": "user", "content": user_msg}])
    return resp.content

# =========================
# 3) Streamlit UI
# =========================
st.set_page_config(page_title="Tistory Writer (ìˆ˜ë™ ë°œí–‰)", page_icon="ğŸ“", layout="wide")
st.title("ğŸ“ LangChain ë¸”ë¡œê·¸ ì´ˆì•ˆ ìƒì„±ê¸°")

with st.sidebar:
    st.header("âš™ï¸ ì„¤ì •")
    openai_model = st.selectbox("OpenAI ëª¨ë¸", ["gpt-4o-mini", "gpt-4o", "gpt-4.1-mini"], index=0)
    temperature = st.slider("ì°½ì˜ì„±(temperature)", 0.0, 1.0, 0.2, 0.1)
    max_web = st.slider("ì›¹ ê²€ìƒ‰ ê²°ê³¼ ìˆ˜ (Tavily)", 3, 10, 5)
    max_papers = st.slider("ë…¼ë¬¸ í›„ë³´ ìˆ˜ (arXiv)", 1, 5, 3)

topic = st.text_area("ì£¼ì œ/í‚¤ì›Œë“œ ì…ë ¥", height=140,
                     placeholder="ì˜ˆ) ìƒì„±í˜• AIì˜ ì „ììƒê±°ë˜ ì ìš© ì‚¬ë¡€ì™€ í•œê³„")

if st.button("ğŸ” ìˆ˜ì§‘ & âœï¸ ì´ˆì•ˆ ìƒì„±", type="primary", use_container_width=True):
    if not topic.strip():
        st.error("ì£¼ì œë¥¼ ì…ë ¥í•˜ì„¸ìš”.")
        st.stop()

    with st.spinner("ìë£Œ ìˆ˜ì§‘ ì¤‘..."):
        web_notes = tavily_search(topic, max_web) if TAVILY_API_KEY else "(Tavily API í‚¤ ì—†ìŒ)"
        paper_notes = arxiv_search(topic, max_papers)

    st.subheader("1) ìë£Œ ìˆ˜ì§‘ ê²°ê³¼")
    with st.expander("ì›¹ ê²€ìƒ‰ ìš”ì•½", expanded=False):
        st.json(web_notes)   # dictë‚˜ JSON ë¬¸ìì—´ì´ë©´ ì˜ˆì˜ê²Œ ì¶œë ¥
    with st.expander("ë…¼ë¬¸ ê²€ìƒ‰ ìš”ì•½", expanded=False):
        st.text(paper_notes)

    with st.spinner("ì´ˆì•ˆ ìƒì„± ì¤‘..."):
        markdown_article = generate_article(topic, web_notes, paper_notes,
                                        model=openai_model, temperature=temperature)

    st.subheader("2) ë§ˆí¬ë‹¤ìš´ ì´ˆì•ˆ (í‹°ìŠ¤í† ë¦¬ì— ë³µì‚¬í•´ ë„£ìœ¼ì„¸ìš”)")
    st.text_area("ë§ˆí¬ë‹¤ìš´ ê²°ê³¼", value=markdown_article, height=500)

    st.info("ğŸ‘‰ ìœ„ ë§ˆí¬ë‹¤ìš´ì„ ë³µì‚¬í•´ì„œ í‹°ìŠ¤í† ë¦¬ ê¸€ì“°ê¸° ì°½(ë§ˆí¬ë‹¤ìš´ ëª¨ë“œ)ì— ë¶™ì—¬ë„£ìœ¼ì„¸ìš”.")

